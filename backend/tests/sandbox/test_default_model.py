#!/usr/bin/env python3
"""
é»˜è®¤æ¨¡å‹é…ç½®æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬ç”¨äºæµ‹è¯•é»˜è®¤æ¨¡å‹é…ç½®æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import os
import sys
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.config import config
from services.llm import make_llm_api_call
from utils.logger import logger

async def test_default_model_config():
    """æµ‹è¯•é»˜è®¤æ¨¡å‹é…ç½®"""
    print("ğŸ§ª æµ‹è¯•é»˜è®¤æ¨¡å‹é…ç½®...")
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    print(f"å½“å‰é»˜è®¤æ¨¡å‹: {config.DEFAULT_MODEL}")
    print(f"ç¯å¢ƒæ¨¡å¼: {config.ENV_MODE.value}")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    env_model = os.getenv("DEFAULT_MODEL")
    if env_model:
        print(f"ç¯å¢ƒå˜é‡ DEFAULT_MODEL: {env_model}")
    else:
        print("ç¯å¢ƒå˜é‡ DEFAULT_MODEL: æœªè®¾ç½®")
    
    return True

async def test_default_model_usage():
    """æµ‹è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹è¿›è¡Œ LLM è°ƒç”¨"""
    print("\nğŸ§ª æµ‹è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹è¿›è¡Œ LLM è°ƒç”¨...")
    
    try:
        # ä½¿ç”¨é»˜è®¤æ¨¡å‹
        response = await make_llm_api_call(
            messages=[
                {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»è‡ªå·±"}
            ],
            model_name=config.DEFAULT_MODEL,
            max_tokens=100,
            temperature=0.7
        )
        
        print("âœ… é»˜è®¤æ¨¡å‹è°ƒç”¨æˆåŠŸ!")
        print(f"ä½¿ç”¨çš„æ¨¡å‹: {config.DEFAULT_MODEL}")
        print(f"å“åº”: {response.choices[0].message.content if hasattr(response, 'choices') else response}")
        return True
        
    except Exception as e:
        print(f"âŒ é»˜è®¤æ¨¡å‹è°ƒç”¨å¤±è´¥: {e}")
        return False

async def test_model_switching():
    """æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åˆ‡æ¢åŠŸèƒ½...")
    
    # æµ‹è¯•ä¸åŒçš„æ¨¡å‹
    test_models = [
        "deepseek/deepseek-chat",
        "anthropic/claude-sonnet-4",
        "openai/gpt-4o-mini"
    ]
    
    results = []
    for model in test_models:
        try:
            print(f"æµ‹è¯•æ¨¡å‹: {model}")
            response = await make_llm_api_call(
                messages=[
                    {"role": "user", "content": "ä½ å¥½"}
                ],
                model_name=model,
                max_tokens=50,
                temperature=0.7
            )
            
            print(f"âœ… {model} è°ƒç”¨æˆåŠŸ")
            results.append(True)
            
        except Exception as e:
            print(f"âŒ {model} è°ƒç”¨å¤±è´¥: {e}")
            results.append(False)
    
    return results

async def test_environment_override():
    """æµ‹è¯•ç¯å¢ƒå˜é‡è¦†ç›–"""
    print("\nğŸ§ª æµ‹è¯•ç¯å¢ƒå˜é‡è¦†ç›–...")
    
    # ä¿å­˜åŸå§‹ç¯å¢ƒå˜é‡
    original_env = os.getenv("DEFAULT_MODEL")
    
    try:
        # è®¾ç½®æ–°çš„ç¯å¢ƒå˜é‡
        os.environ["DEFAULT_MODEL"] = "deepseek/deepseek-chat"
        
        # é‡æ–°åŠ è½½é…ç½®
        from importlib import reload
        import utils.config
        reload(utils.config)
        
        # è·å–æ–°çš„é…ç½®
        new_config = utils.config.config
        print(f"ç¯å¢ƒå˜é‡è¦†ç›–åçš„é»˜è®¤æ¨¡å‹: {new_config.DEFAULT_MODEL}")
        
        # æµ‹è¯•è°ƒç”¨
        response = await make_llm_api_call(
            messages=[
                {"role": "user", "content": "æµ‹è¯•ç¯å¢ƒå˜é‡è¦†ç›–"}
            ],
            model_name=new_config.DEFAULT_MODEL,
            max_tokens=50
        )
        
        print("âœ… ç¯å¢ƒå˜é‡è¦†ç›–æµ‹è¯•æˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"âŒ ç¯å¢ƒå˜é‡è¦†ç›–æµ‹è¯•å¤±è´¥: {e}")
        return False
        
    finally:
        # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
        if original_env:
            os.environ["DEFAULT_MODEL"] = original_env
        else:
            os.environ.pop("DEFAULT_MODEL", None)
        
        # é‡æ–°åŠ è½½é…ç½®
        from importlib import reload
        import utils.config
        reload(utils.config)

async def test_project_naming_function():
    """æµ‹è¯•é¡¹ç›®å‘½åå‡½æ•°æ˜¯å¦ä½¿ç”¨é»˜è®¤æ¨¡å‹"""
    print("\nğŸ§ª æµ‹è¯•é¡¹ç›®å‘½åå‡½æ•°...")
    
    try:
        # æ¨¡æ‹Ÿé¡¹ç›®å‘½åå‡½æ•°çš„é€»è¾‘
        from agent.api import generate_and_update_project_name
        
        # æ£€æŸ¥å‡½æ•°æ˜¯å¦ä½¿ç”¨äº† config.DEFAULT_MODEL
        import inspect
        source = inspect.getsource(generate_and_update_project_name)
        
        if "config.DEFAULT_MODEL" in source:
            print("âœ… é¡¹ç›®å‘½åå‡½æ•°å·²ä½¿ç”¨ config.DEFAULT_MODEL")
            return True
        else:
            print("âŒ é¡¹ç›®å‘½åå‡½æ•°ä»åœ¨ä½¿ç”¨ç¡¬ç¼–ç æ¨¡å‹")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•é¡¹ç›®å‘½åå‡½æ•°å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹é»˜è®¤æ¨¡å‹é…ç½®æµ‹è¯•...")
    print("=" * 50)
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        test_default_model_config,
        test_default_model_usage,
        test_model_switching,
        test_environment_override,
        test_project_naming_function
    ]
    
    results = []
    for test in tests:
        try:
            result = await test()
            if isinstance(result, list):
                results.extend(result)
            else:
                results.append(result)
        except Exception as e:
            print(f"âŒ æµ‹è¯• {test.__name__} å‡ºç°å¼‚å¸¸: {e}")
            results.append(False)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = sum(results)
    total = len(results)
    
    for i, (test, result) in enumerate(zip(tests, results)):
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{i+1}. {test.__name__}: {status}")
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! é»˜è®¤æ¨¡å‹é…ç½®å·¥ä½œæ­£å¸¸!")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    return passed == total

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.setLevel("INFO")
    
    # è¿è¡Œæµ‹è¯•
    try:
        success = asyncio.run(main())
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿è¡Œå‡ºç°å¼‚å¸¸: {e}")
        sys.exit(1)
